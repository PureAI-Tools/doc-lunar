---
title: 'Welcome to Lunar'
description: 'Distill, route, and deploy LLMs from one platform'
---

## Lunar Platform

Lunar offers a complete set of tools for developers who want to distill, route, and deploy AI models. Our platform provides:

<CardGroup cols={2}>
  <Card
    title="Lunar SDK"
    icon="code"
    href="/lunar/overview"
  >
    Python & TypeScript SDK for LLM inference with intelligent routing, fallbacks, cost tracking, and built-in evaluations.
  </Card>
  <Card
    title="GPU Instances"
    icon="server"
    href="/pricing/instance-tiers"
  >
    Deploy and run open-source models on dedicated NVIDIA GPUs, from L4 to H200.
  </Card>
</CardGroup>

## Platform Features

<AccordionGroup>
  <Accordion title="Lunar SDK: OpenAI-Compatible LLM Access">
    Access 12+ LLM providers through a single API. Features smart routing with AI task classification, automatic fallbacks, per-request cost tracking, and a comprehensive evaluation framework with 15+ built-in scorers.
  </Accordion>
  <Accordion title="GPU Instances: Deploy Any Model">
    Run open-source models like LLaMA, Qwen, DeepSeek, and more on dedicated GPU instances. Choose from 6 tiers ranging from NVIDIA L4 (24GB) to H200 clusters (1128GB).
  </Accordion>
</AccordionGroup>

## Get Started

<Tabs>
  <Tab title="Python">
    <Steps>
      <Step title="Install the SDK">
        ```bash
        pip install lunar-sdk
        ```
      </Step>
      <Step title="Set your API key">
        ```bash
        export LUNAR_API_KEY="pk_live_your_key"
        ```
      </Step>
      <Step title="Make your first request">
        ```python
        from lunar import Lunar

        client = Lunar()
        response = client.chat.completions.create(
            model="auto",
            messages=[{"role": "user", "content": "Hello!"}]
        )
        print(response.choices[0].message.content)
        ```
      </Step>
    </Steps>

    <Card title="Full Quickstart Guide" icon="rocket" href="/lunar/quickstart">
      Learn more about the Lunar SDK
    </Card>
  </Tab>

  <Tab title="TypeScript">
    <Steps>
      <Step title="Install the SDK">
        ```bash
        npm install lunar-sdk
        ```
      </Step>
      <Step title="Make your first request">
        ```typescript
        import Lunar from "lunar-sdk";

        const client = new Lunar({ apiKey: "pk_live_your_key" });

        const response = await client.chat.completions.create({
          model: "auto",
          messages: [{ role: "user", content: "Hello!" }],
        });
        console.log(response.choices[0].message.content);
        ```
      </Step>
    </Steps>
  </Tab>

  <Tab title="REST API">
    <Steps>
      <Step title="Get your API key">
        Sign up at the Console and generate a `pk_live_` API key.
      </Step>
      <Step title="Make a request">
        ```bash
        curl https://api.lunar.dev/v1/chat/completions \
          -H "Authorization: Bearer pk_live_YOUR_KEY" \
          -H "Content-Type: application/json" \
          -d '{
            "model": "auto",
            "messages": [{"role": "user", "content": "Hello!"}],
            "stream": true
          }'
        ```
      </Step>
    </Steps>

    <Card title="API Reference" icon="book" href="/lunar/api/reference">
      Full REST API documentation
    </Card>
  </Tab>

  <Tab title="GPU Instances">
    <Steps>
      <Step title="Choose your model">
        Browse 30+ pre-configured models from LLaMA, Qwen, DeepSeek, and more.
      </Step>
      <Step title="Select an instance tier">
        Choose from XS (~$0.20/h) to XXL (~$30/h) based on your model size.
      </Step>
      <Step title="Deploy and use">
        Deploy with one click and access via the Lunar SDK or REST API.
      </Step>
    </Steps>

    <Card title="View Instance Tiers" icon="server" href="/pricing/instance-tiers">
      See all GPU options and pricing
    </Card>
  </Tab>

  <Tab title="CLI">
    <Steps>
      <Step title="Install the CLI">
        ```bash
        pip install lunar-cli
        ```
      </Step>
      <Step title="Authenticate">
        ```bash
        lunar auth login --api-key pk_live_YOUR_KEY
        ```
      </Step>
      <Step title="Distill and deploy">
        ```bash
        lunar distill create --teacher gpt-4o --student llama-3.2-3b
        lunar deploy --model my-distilled-model --gpu L4
        ```
      </Step>
    </Steps>
  </Tab>
</Tabs>

## Pricing

| Tier | GPU | VRAM | Price | Best For |
|------|-----|------|-------|----------|
| XS | 1x L4 | 24GB | ~$0.20/h | 7B-13B models |
| S | 1x L40S | 48GB | ~$0.60/h | 13B-34B models |
| M | 4x A10G | 96GB | ~$1.80/h | 70B INT4 |
| L | 4x L40S | 192GB | ~$3.50/h | 70B FP16 |
| XL | 8x A100 | 320-640GB | ~$12/h | 180B models |
| XXL | 8x H100/H200 | 640-1128GB | ~$20-30/h | 405B models |

<Card title="Full Pricing Details" icon="credit-card" href="/pricing/overview">
  View complete pricing information
</Card>

## Community and Support

<CardGroup cols={2}>
  <Card
    title="Discord"
    icon="discord"
    href="https://discord.gg/thyZx5GkFV"
  >
    Join our community to get help and share experiences.
  </Card>
  <Card
    title="GitHub"
    icon="github"
    href="https://github.com/lunar-ai"
  >
    Contribute to development and report issues.
  </Card>
</CardGroup>
